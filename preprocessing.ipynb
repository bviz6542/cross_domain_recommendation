{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BK9_pYEH4cee"
   },
   "source": [
    "# Preprocessing of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erANnFLY4cet"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import essay\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYWuGPPh4cey"
   },
   "outputs": [],
   "source": [
    "def mbti_to_big5(mbti):\n",
    "    # check https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator\n",
    "    # in mbti (myers briggs) ther is invrovert vs. extrovert\n",
    "    # which corellates with Extroversion in BIG FIVE\n",
    "    mbti = mbti.lower()\n",
    "    cEXT, cNEU, cAGR, cCON, cOPN = 0,np.NaN,0,0,0\n",
    "    if mbti[0] == \"i\":\n",
    "        cEXT = 0\n",
    "    elif mbti[0] == \"e\":\n",
    "        cEXT = 1\n",
    "\n",
    "    # in mbti (myers briggs) ther is I*N*TUITION vs SENSING\n",
    "    # which corellates with OPENNESS in BIG FIVE\n",
    "    if mbti[1] == \"n\":\n",
    "        cOPN = 1\n",
    "    elif mbti[1] == \"s\":\n",
    "        cOPN = 0   \n",
    "\n",
    "    # in mbti (myers briggs) ther is THINKER vs FEELER\n",
    "    # which corellates with AGREEABLENESS in BIG FIVE\n",
    "    if mbti[2] == \"t\":\n",
    "        cAGR = 0\n",
    "    elif mbti[2] == \"f\":\n",
    "        cAGR = 1\n",
    "\n",
    "    # in mbti (myers briggs) ther is JUDGER vs PERCEIVER\n",
    "    # which corellates with CONSCIENTIOUSNESS in BIG FIVE (worst corellation)\n",
    "    # especially bec. orderlyness corellates with conscientiousness\n",
    "    if mbti[3] == \"p\":\n",
    "        cCON = 0\n",
    "    elif mbti[3] == \"j\":\n",
    "        cCON = 1\n",
    "\n",
    "    return cEXT, cNEU, cAGR, cCON, cOPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arIePJ2R4ce1"
   },
   "outputs": [],
   "source": [
    "def remove_unemotional_scentences(emotional_words, text_as_one_string):\n",
    "    reduced_s = \"\"\n",
    "    scentences = re.split('(?<=[.!?]) +', text_as_one_string)\n",
    "    for s in scentences:\n",
    "        if any(e in s for e in emotional_words):\n",
    "            reduced_s = reduced_s + s + \" \"\n",
    "        else:\n",
    "            pass\n",
    "    return reduced_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_YUbZTc4ce2"
   },
   "outputs": [],
   "source": [
    "# simply put every row of our read dataframe into a list of \n",
    "# the object \"Essay\"\n",
    "# remove data from list substract\n",
    "def create_essays(df, subtract=None):\n",
    "    essays = []\n",
    "    for index, row in df.iterrows():\n",
    "        essays.append(essay.Essay(row.TEXT, row.cEXT, row.cNEU, row.cAGR, row.cCON, row.cOPN))  \n",
    "\n",
    "    # remove scentences which do not contain emotionally charged words \n",
    "    # from the emotional lexicon\n",
    "    if subtract != None:\n",
    "        for x in essays:\n",
    "            x.filtered_text = remove_unemotional_scentences(emotional_words, x.clean_text)\n",
    "\n",
    "    return essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqTQTc6I4ce3"
   },
   "source": [
    "# Loading the essays from paper\n",
    "## scientific gold standard\n",
    "## https://sentic.net/deep-learning-based-personality-detection.pdf\n",
    "### (scientific gold standard \"stream of counsciousness\" essays labeled with personality traits of the big five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CV-V63dG4ce4",
    "outputId": "ec67f138-e2cd-4cd6-c856-1c05e23770ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>I'm home. wanted to go to bed but remembe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>Stream of consiousnesssskdj. How do you s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>It is Wednesday, December 8th and a lot has be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>Man this week has been hellish. Anyways, now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>I have just gotten off the phone with brady. I...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2467 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TEXT  cEXT  cNEU  cAGR  \\\n",
       "0     Well, right now I just woke up from a mid-day ...     0     1     1   \n",
       "1     Well, here we go with the stream of consciousn...     0     0     1   \n",
       "2     An open keyboard and buttons to push. The thin...     0     1     0   \n",
       "3     I can't believe it!  It's really happening!  M...     1     0     1   \n",
       "4     Well, here I go with the good old stream of co...     1     0     1   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "2462       I'm home. wanted to go to bed but remembe...     0     1     0   \n",
       "2463       Stream of consiousnesssskdj. How do you s...     1     1     0   \n",
       "2464  It is Wednesday, December 8th and a lot has be...     0     0     1   \n",
       "2465  Man this week has been hellish. Anyways, now i...     0     1     0   \n",
       "2466  I have just gotten off the phone with brady. I...     0     1     1   \n",
       "\n",
       "      cCON  cOPN  \n",
       "0        0     1  \n",
       "1        0     0  \n",
       "2        1     1  \n",
       "3        1     0  \n",
       "4        0     1  \n",
       "...    ...   ...  \n",
       "2462     1     0  \n",
       "2463     0     1  \n",
       "2464     0     0  \n",
       "2465     0     1  \n",
       "2466     0     1  \n",
       "\n",
       "[2467 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we read in the data from \"essays.csv\" and \n",
    "# \"essays.csv\" contains all essays with classification \n",
    "df_essays = pd.read_csv('data/training/essays.csv', encoding='cp1252', delimiter=',', quotechar='\"')\n",
    "\n",
    "# for every essay, we replace the personalitiy categories \n",
    "# of the essay wich are \"y\" and \"n\" with \"1\" and \"0\" \n",
    "for e in df_essays.columns[2:7]:\n",
    "    df_essays[e] = df_essays[e].replace('n', '0')\n",
    "    df_essays[e] = df_essays[e].replace('y', '1')\n",
    "    # not sure if we need this line: furter investigation possible:\n",
    "    df_essays[e] = pd.to_numeric(df_essays[e])\n",
    "\n",
    "df_essays = df_essays[[\"TEXT\", \"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]]\n",
    "df_essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_58zLK6p4cfD"
   },
   "source": [
    "# Load Emotional Lexicon to substract from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arROzdSf4cfE"
   },
   "outputs": [],
   "source": [
    "# also from \"Emotional_Lexicon.csv\" we read in the data, which is a list of words and \n",
    "# has several categories of emotions. \n",
    "# anger - anticipation - disgust - fear - joy - negative - positive \n",
    "# - sadness - surprise - trust - Charged\n",
    "df_lexicon = pd.read_csv('data/training/Emotion_Lexicon.csv', index_col=0)\n",
    "\n",
    "\n",
    "# some of the words have no emotional category, \n",
    "# so let's remove them as they have no use to us.\n",
    "# can be improved by not even loading them when all columns are 0. maybe later.\n",
    "df_lexicon = df_lexicon[(df_lexicon.T != 0).any()]\n",
    "emotional_words = df_lexicon.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "to4N9b_S4cfF"
   },
   "source": [
    "# Concatinate the datasets for 3 different data to work with and compare to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ig5Wjs3q4cfF"
   },
   "source": [
    "## Create Data Base 1 - only esseys.csv - and save as object list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4yLQXCq4cfG",
    "outputId": "19f913ae-2168-4c85-f22b-156afb6518b7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved entries:  2467\n"
     ]
    }
   ],
   "source": [
    "# save preprocessed data by converting into OBJECT essay and save with pickle and removing non emotional scentences\n",
    "essays = create_essays(df_essays, emotional_words)\n",
    "pickle.dump(essays, open( \"essays/essays2467.p\", \"wb\"))\n",
    "print(\"saved entries: \", len(essays))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
